<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2017-05-09 Tue 01:03 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>The Human Automaton</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Justen Rickert" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2013 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">The Human Automaton</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org009ebaa">1. Purpose</a></li>
<li><a href="#orgd321819">2. Language Construction</a>
<ul>
<li><a href="#org44ca3ac">2.1. First-order Language</a></li>
<li><a href="#orgd3e5539">2.2. Context-free Grammars</a></li>
<li><a href="#org815f28c">2.3. Computing Languages</a></li>
</ul>
</li>
<li><a href="#org517f2d5">3. The Human Automaton</a>
<ul>
<li><a href="#org641979e">3.1. The Life of the Human</a></li>
<li><a href="#org79d6f4b">3.2. Comparison to Mathematical Models</a></li>
<li><a href="#org815ba0d">3.3. AI-hard</a></li>
</ul>
</li>
<li><a href="#org0779bee">4. Context Generation</a>
<ul>
<li><a href="#orgce0a257">4.1. Rules of Inference</a></li>
<li><a href="#org613296a">4.2. Language Generation</a></li>
<li><a href="#orgdaf8e70">4.3. Logic Generation</a></li>
<li><a href="#org857e980">4.4. Context Generation</a></li>
</ul>
</li>
<li><a href="#org08e07ed">5. Bibliography</a></li>
</ul>
</div>
</div>
<p>
\pagebreak
</p>

<div id="outline-container-org009ebaa" class="outline-2">
<h2 id="org009ebaa"><span class="section-number-2">1</span> Purpose</h2>
<div class="outline-text-2" id="text-1">
<p>
The ultimate purpose of this paper is to derive a fashion in which a machine,
or <code>automaton</code>, may derive the meaning behind, or understand, human language
sentences. A general sentence notwithstanding context does not mean anything,
yet humans have somehow come to be able to throw sentences around at each
other in such a way that their conversations are meaningful. That is to say
that people have come to develop a rapport with each other wherein
seemingly-random phrases of a speaker, even when devoid of <code>context</code>, somehow
are meaningful to, or verifiable by, a listener. The penultimate purpose of
this paper is therefore to derive a construction of <code>context</code> by a which a
machine may use to begin to understand the seemingly-random phrases of a
speaker speaking to it.
</p>
</div>
</div>

<div id="outline-container-orgd321819" class="outline-2">
<h2 id="orgd321819"><span class="section-number-2">2</span> Language Construction</h2>
<div class="outline-text-2" id="text-2">
<p>
A mathematical framework for language construction is important to the
derivation of the <code>computational model</code> to be defined. In particular the theory
of mathematical logical and the theory of computation happen to be very
important to this language construction.
</p>

<p>
There will be a concatenation of two varieties of languages in mathematics
used to describe the way in which <code>natural</code>&#x2014;that is to say
<i>human</i>---\(\verb|languages|\) and <code>contexts</code> can be modeled. To clarify what is
meant by <code>context</code> here, imagine the statement "I am sad because my dog died."
It may be clear to the reader why sadness can be determined by the possibility
of the dog dying. It is probably because the reader has either himself had a
dog, or has at some point seen or understood the joy that having a dog can
bring to the person (perhaps the reader has seen or read <i>Where the Red Fern
Grows</i>). Imagine, however, a culture that never came to the point of
domesticating dogs. A person of such a culture reading such a statement would
not understand the interconnected nature that exists between <i>being sad</i> and
<i>having a dog die</i>. A person who understands the statement has the <code>context</code>
available to him to understand the logic of why <i>a dog dying</i> could imply <i>being
sad</i>. In any case, the derivation of this logic will be described according to
the logic of a mathematical <code>first-order language</code>.
</p>
</div>

<div id="outline-container-org44ca3ac" class="outline-3">
<h3 id="org44ca3ac"><span class="section-number-3">2.1</span> First-order Language</h3>
<div class="outline-text-3" id="text-2-1">
<p>
Let's first consider a mathematical language of logic, a <code>first-order language</code>
consisting   of    a   finite    collection   of   sentence    symbols,   say
\(P,P_{1},\dots,P_{n}\) or \(Q,Q_{1},\dots,Q_{n}\);  the negation symbol, \(\neg\);
and the  symbol for implication,  \(\rightarrow\). A single sentence  symbol is
considered  a valid  statement. The  negation symbol,  \(\neg\), acts  upon one
sentence symbol, while the  implication symbol, \(\rightarrow\), joins together
two sentence symbols.  The following are all valid statements  in the defined
<code>first-order language</code>:
</p>
<ul class="org-ul">
<li>\(P\)</li>
<li>\(\neg P\)</li>
<li>\(P \rightarrow Q\)</li>
</ul>

<p>
If \(P\) is considered  to be the statement "It is  raining," then the negation
of the statement,  <i>i.e.</i> \(\neg P\), becomes the statement  "It is not raining."
When the statement \(Q\)  is considered to be "The ground  is wet outside," the
implication of the two statements, <i>i.e.</i>  \(P \rightarrow Q\), becomes "If it is
raining,  then the  ground is  wet outside."  When the  statement \(P\)  holds,
meaning when it  <i>is</i> raining outside, it  must be that the  statement \(Q\) must
hold as  well, as it makes  sense in the <code>natural  language</code>&#x2014;English, in this
particular case&#x2014;that the statement \(P \rightarrow  Q\) holds, as it would be
impossible for the ground <i>not</i> to be wet outside if it is raining. So when the
statement \(P\) holds and the statement \(P \rightarrow Q\) holds, then statement
\(P\) derives statement \(Q\), written \(P \vdash Q\).
</p>

<p>
Statements  constructed  more  complexly than  this  require  parenthesizing,
otherwise  the statements  may be  read ambiguously.  Consider the  ambiguous
statement \(P_1 \rightarrow P_2 \rightarrow P_3\). Let \(P_1\) to be "Somebody is
at the door," let \(P_2\) to be "The dog is barking at the door," and let \(P_3\)
to  be "The  man  is angry  at  the dog."  There are  two  different ways  to
parenthesize this statement, each having a different effect on the underlying
meaning of the  statement. They are \(P_1 \rightarrow  (P_2 \rightarrow P_3)\),
or \((P_1 \rightarrow P_2) \rightarrow P_3\).
</p>

<p>
Consider \(P_2 \vdash P_3\) holds, or "The  dog is barking at the door" and "If
the dog is barking at the door, then the man is angry at the dog," so that it
can be  derived that \(P_3\)  holds, as  it makes sense  that the man  is angry
because the  dog is  barking. This corresponds  to a  parenthesized statement
\(P_1  \rightarrow  (P_2  \rightarrow  P_3)\),   where  \(P_2\)  holds.  In  this
construction the complete derivation of  the statement does not make complete
sense from  a <code>natural language</code>  perspective because the statement  \(P_1\), the
somebody being  at the door,  does not have  any implication on  the scenario
according to the  definition of implication in the  <code>first-order language</code>. The
dog has already been defined to be barking at the door, and there has been no
logical implication that there  is somebody at the door. The  dog may just be
barking at the door for no reason.
</p>

<p>
The  other parenthesized  statement \((P_1  \rightarrow P_2)  \rightarrow P_3\)
means something different.  Consider \(P_1 \vdash P_2\) holds,  or "Somebody is
at the door" holds  and "If somebody is at the door, then  the dog is barking
at the door" holds, so that \(P_2\) is derivable. As the dog must be barking at
the somebody who is  at the door, then it must be that  the dog is barking at
the door. Furthermore since \((P_1 \rightarrow P_2)\) holds, and it is that the
complete statement  \((P_1 \rightarrow  P_2) \rightarrow  P_3\) holds,  as this
complete statement makes sense given that the man must be mad because the dog
is barking at  the door, then it  must be that \((P_1  \rightarrow P_2) \vdash
   P_3\).
</p>

<p>
In either  case, the  point is  that the two  statements considered  by their
different parenthesis  constructions carry along with  them different meaning
(even without  the consideration that either  \(P_1 \vdash P_2\) holds  or \(P_2
   \vdash  P_3\) holds).  At  the  heart of  this  <code>first-order  language</code> are  the
theorems of soundness  and completeness for propositional  logic. The theorem
of soundness means that given  a properly-constructed sentence, as previously
talked about, there is a sound derivation  of the sense that the statement is
trying to convey.  The theorem for completeness requires more  of an involved
explanation in  practice, but is  the converse  of the theorem  of soundness:
Given the sense  of a statement, there is  a properly-construct-able sentence
to which there exists a statement  in the <code>first-order language</code> describing the
sense of a statement which can then be compared to a <code>natural language</code>.
</p>
</div>
</div>

<div id="outline-container-orgd3e5539" class="outline-3">
<h3 id="orgd3e5539"><span class="section-number-3">2.2</span> Context-free Grammars</h3>
<div class="outline-text-3" id="text-2-2">
<p>
The notion of grammar is fairly mathematical naturally, but perhaps that is
the case as mathematics steals a lot from <code>natural language</code> in its derivation.
In any case, it is hard not to make an analogy between the two when such
notions as subject, object, predicate, copula, <i>etc.</i> are nearly identical
without needing to compare them by complex methods.
</p>

<p>
Going into mathematical details, it can be said that there is a
correspondence between mathematical statements and ordinary English
sentences. Perhaps one point, however, that needs to be made more clear is
the tricky ability that <code>natural language</code> has over mathematical statements in
differentiating objects. English has two articles, <i>a/an</i> and <i>the</i>, and the
usefulness of these articles is without limit; though probably not many
people stop to think about the complexity that actually goes into using these
articles appropriately, and how naturally people come to be able to use them
so effectively. Furthermore, one could make conversation in a similar fashion
about the demonstrative pronouns, <i>this</i>, <i>that</i>, <i>these</i>, and <i>those</i>, but these
articles aid more to the complexity of <code>natural language</code> than the convenience
of the well-spoken English user. Sentences of <code>natural language</code> are equally
capable of existing without the addition of these pronouns, or other
pronouns; but prior to these there must first be a notion of <code>context</code> by which
pronouns may replace what they wish.
</p>

<p>
Articles affect nouns. A specific thing in the world can be defined, as <i>the</i>
<i>noun</i> in question, or can remain to be indefinite, as <i>a noun</i> to be questioned.
<i>A noun</i> can affect things in the universe by using <i>a verb</i>. <i>The noun</i> prior to <i>a
verb</i> either acts in such a way that it affects <i>a different noun</i>, or it acts
intransitively so as to only modify itself. <i>A preposition</i> may also more
greatly specify the qualities of <i>a noun</i>.
</p>

<p>
These parts of speech, from a mathematical perspective, can be recursively
linked together via a language construction called a <code>context-free grammar</code>.
The following is an example of a <code>context-free grammar</code> for <code>natural language</code>
construction:
</p>
<p>
The following is an example derivation:
</p>
<p>
Since the rules of grammar make more sense to people naturally, the specifics
of the <code>context-free grammar</code> will be kept to a minimum. We must trust
ourselves to be capable of generating <code>natural language</code> statements, and leave
the specifics of a <code>context-free grammar</code> to the later implementation details.
There is a more important notion of <code>context generation</code> to come later that
will clear any confusions on the subject. At the moment focus will be placed
on the specifics of the <code>computational model</code> used to compute and verify
<code>natural language</code> sentences.
</p>
</div>
</div>

<div id="outline-container-org815f28c" class="outline-3">
<h3 id="org815f28c"><span class="section-number-3">2.3</span> Computing Languages</h3>
<div class="outline-text-3" id="text-2-3">
<p>
<code>Computational complexity</code> is measured by a machine's ability to understand
languages. The model below describes the general idea behind the derivation
process. In order that a <code>computational model</code> can exist, there must first be a
<code>natural language</code> which can be reduced to a language generated by some
<code>context-free grammar</code>. The statements generated by the <code>context-free grammar</code>
can take the place of <code>sentence symbols</code> in the <code>first-order language</code>. This
reduction process corresponds to a reduction of <code>natural language</code> to a
<code>mathematical language</code>. From this point, since <code>mathematical languages</code> that
exist are such that they abide by the soundness and completeness theorems,
the problem can be further reduced to an algorithm which can be run on some
kind of <code>computational model</code>. When a <code>computational model</code> emulates the desired
<code>natural language</code> sentence, the statement is said to be verified.
</p>


<div class="figure">
<p><img src="languagemodel.png" alt="languagemodel.png" />
</p>
</div>

<p>
Considering the <code>context-free grammar</code> in a prior section, the following
statements may be generated:
</p>
<dl class="org-dl">
<dt>P<sub>1</sub></dt><dd>A boy likes a girl with a flower.</dd>
<dt>P<sub>2</sub></dt><dd>The girl touches a flower.</dd>
<dt>P<sub>3</sub></dt><dd>The boy sees the girl with a flower.</dd>
<dt>P<sub>4</sub></dt><dd>The boy likes the girl.</dd>
</dl>

<p>
In ordinary English, we can make the statement: "If a boy likes a girl with a
flower, and the girl touches a flower, and the boy sees the girl with a
flower, then the boy likes the girl." The logical implication is that the
three statements \(P_1\), \(P_2\), and \(P_3\) are sufficient for the statement \(P_4\)
to be true, though perhaps the statement is a little contrived. An ordinary
human would perhaps like to say the more natural phrase: "That boy must like
that girl over there with the flower." The fact that the boy likes the girl
is evident in the statement (or rather the speaker is testing the conviction
of such a statement); just as well, the fact that there <i>is</i> a girl is evident
(as per the usage of the demonstrative pronoun). However the idea that a boy
<i>would</i> like a girl would be naturally formulated by <code>context</code>&#x2014;the ordinary
human speaker's most prominent point of contention is in the utilization of
the word <i>must</i>, and it is probably that he/she is afterwards awaiting the
agreement or rejection of the statement by the listener. Furthermore the idea
that the girl <i>touching</i> a flower implies that the girl is <i>with</i> a flower would
be formulated by <code>context</code> as well&#x2014;imagine that the scene has many girls but
there is only one flower, then the girl with the flower would be unique
(which is sufficient condition for that statement to be true).
</p>

<p>
In any case, the reduction of the statement from the <code>natural language</code> to a
<code>first-order language</code> is
</p>

<p>
\[(P_1 \land P_2 \land P_3) \vdash P_4.\]
</p>

<p>
The binary connective symbol, &and;, corresponds to the English conjunctive, <i>and</i>.
However this statement does not use the example <code>first-order language</code>
previously described. This <code>first-order statement</code> is (by a bit of hand-waving)
tautologically equivalent to
</p>

<p>
\[\neg(P_1 \rightarrow (P_2 \rightarrow \neg P_3)) \vdash P_4.\]
</p>

<p>
From this point, we can begin the derivation process by asserting that \(P_4\)
must hold. That is, let the statement "The boy likes the girl" hold.
(Remember this is what the speaker would have been awaiting if there were
<code>context</code> given to the statement. It was his/her conviction that the girl in
question <i>must</i> like the boy in question.) We have derived from our <code>natural
   language</code> that \(\neg(P_1 \rightarrow (P_2 \rightarrow \neg P_3)) \vdash P_4\) holds,
and have already determined that \(P_4\) holds, so that it must be that \(\neg(P_1
   \rightarrow (P_2 \rightarrow \neg P_3))\) holds. This statement, \(\neg(P_1 \rightarrow (P_2
   \rightarrow \neg P_3))\), holds whenever \(P_1 \rightarrow (P_2 \rightarrow \neg P_3)\) does not.
This negated statement does not hold if it is that \(P_1\) holds but \((P_2
   \rightarrow \neg P_3)\) does not. At this point, we can state that \(P_1\) holds so it must be
true that "A boy likes a girl with a flower." The statement \((P_2 \rightarrow
   \neg P_3)\) does not hold if it is that \(P_2\) does hold, but the statement \(\neg P_3\)
does not, or rather that \(P_3\) does hold. From this point we can state that
\(P_2\) holds so it is true that "The girl touches a flower," as well as that
\(P_3\) holds so it is true that "The boy sees the girl with the flower." In sum
the statement reduced to a <code>first-order language</code> statement is valid, and would
be accepted by another machine capable of generating the statement. Any other
machine of similar <code>computational complexity</code> <i>is</i> capable of generating the
statement; therefore this <code>natural language</code> sentence is verifiable.
</p>
</div>
</div>
</div>

<div id="outline-container-org517f2d5" class="outline-2">
<h2 id="org517f2d5"><span class="section-number-2">3</span> The Human Automaton</h2>
<div class="outline-text-2" id="text-3">
<p>
Let's step away from the notion of language construction for a moment to talk
about the humanity that our language construction is trying to simulate. The
metaphysical question is whether or not there is some computational machine
able to simulate the conversation of humans. The road taken thus far has
talked about some of the building blocks that make <code>natural languages</code> resemble
the chosen <code>mathematical languages</code> in some way, but has not yet come to touch
on the ways in which humanity uses language.
</p>

<p>
Language is about communication. Language was developed as a method of
delivering ideas between people or peoples. Language is the method by which we
have come to comprehend intelligence. Were it not for language, then we would
have no way to consider the complexity of the world around us; and it is with
language that we take the simple things around us and try to compute more
complex ideas, which in turn generates more complex language statements. The
<code>human automaton</code> uses a similar concept. The <code>human automaton</code> starts from some
<code>context</code> generated from human understanding, and attempts to create new idea
from it using logic. Listening to another person speak is really just
verification of <code>natural language statements</code>. A typical conversation will have
a speaker explaining some situation or some new idea, a new <code>context</code>, until the
listener of the conversation interrupts him; either to verify comprehension of
the idea or situation, or to ask that a certain point be elaborated on or
reiterated so that the explanation can continue again until the new <code>context</code> is
understood. At the end of the conversation the listener will have generated
new ideas as a result of understanding this new <code>context</code>, and he/she can now be
a speaker for his/her own, now greater, <code>context</code>.
</p>

<p>
At the moment, there is not a model for generating this kind of <code>context</code>, and
so there is not anything in place allowing a possible machine to generate
conversation. That is, even when using proper, grammatically-correct language,
there cannot be any meaning behind statements generated by a <code>context-free
  grammar</code>. The <code>context-free grammar</code> can generate <code>natural language</code> statements,
these statements are able to be composed within a <code>first-order language</code>, and
there is at least some meaning behind the words in that the words act as a
part of speech valid according to the sentence construction; however there is
no meaning behind the statements, as there is no <code>context</code> given to them&#x2014;they
are, at this point, randomly generated statements placed arbitrarily, as
<code>sentence symbols</code>, into a <code>first-order language</code>. The unique idea behind the
<code>human automaton</code> is that there is no beginning <code>context</code> to which new <code>context</code> is
generated around. A human is born one day, knows nothing, and then someday
magically comes to understand the <code>context</code> of the world around; he/she somehow
emerges into the world of conscience conversation, then begins constructing
verifiable, grammatically-correct, <code>natural language</code> sentences.
</p>
</div>

<div id="outline-container-org641979e" class="outline-3">
<h3 id="org641979e"><span class="section-number-3">3.1</span> The Life of the Human</h3>
<div class="outline-text-3" id="text-3-1">
<p>
The life of the human starts at birth. Though let this be a disambiguation
from the life of the man, as the life of the man begins when the human has
fully learned <i>thinking for acting</i>. Consider this an important distinction, as
the young human, the baby, cannot <i>think</i> fully yet and so cannot fully <i>act</i>
either. The baby does not learn to <i>think</i> and <i>act</i> fully until he/she becomes a
man, or rather he/she fully becomes a man/woman the day that he/she learns to
<i>think</i> and <i>act</i>. The following is a <code>transition diagram</code> emphasizing this
process<sup><a id="fnr.1" class="footref" href="#fn.1">1</a></sup>:
</p>

<div class="figure">
<p><img src="human.png" alt="human.png" />
</p>
<p><span class="figure-number">Figure 2: </span>generalized human upbringing</p>
</div>

<p>
In same fashion, the <code>transition diagram</code> will act as the <code>context</code> by which the
<code>human automaton</code> operates. The idea of this operational process might be a
little more involved in considering the complexity of the <i>thinking for acting</i>
<code>transition</code>. That is, the <code>transition</code> can be expanded. Any <code>transition</code> on the
<code>transition diagram</code> has the capacity to be expanded.
</p>

<div class="figure">
<p><img src="humansimplified.png" alt="humansimplified.png" />
</p>
<p><span class="figure-number">Figure 3: </span>\(\textit{thinking for acting } \verb|transition\)</p>
</div>

<p>
Since people are different, any single person will take their own <i>thinking
for acting</i> <code>transition</code> differently. That is to say, one may take their
<i>thinking for acting</i> <code>transition</code> as a series of important <code>transitions</code> in their
life in such a way that is unique to themselves. Obviously, the baby must
first become a child before he/she becomes a teenager, and, maybe, the child
will become interested in high school marching or concert band as a teenager
before he/she finally becomes a man. Following this example is another
<code>transition diagram</code>:
</p>

<div class="figure">
<p><img src="humansimpletransition.png" alt="humansimpletransition.png" />
</p>
</div>

<p>
This <code>transition diagram</code> is <code>singular</code>. It represents the life of only one
individual. There is only one clear path to describe the series of
<code>transitions</code>, and while this <code>transition diagram</code> may not be capable of
describing every single person's identity throughout his/her life, it is
certainly capable of describing one person's. Therefore the description of
this <code>transition diagram</code> is limited in some way. Ideally this particular
person who ascribes his/her life to this <code>transition diagram</code> would like to have
for himself more options, and certainly there could be a plethora of these
options (and furthermore any of these options could be expanded, as any
<code>transition</code> on the <code>transition diagram</code> has the capacity to be expanded). Thus
where this <code>transition diagram</code> is <code>singular</code> and fairly simple, there is a
<code>transition diagram</code> where the <code>transitions</code> are <code>variable</code>. Continuing the example
is a <code>variable</code><sup><a id="fnr.2" class="footref" href="#fn.2">2</a></sup>, <code>transition diagram</code> describing the life of the child as
the superposition of his/her life being a high school football quarterback with
that of his/her life being a high school band geek.
</p>

<div class="figure">
<p><img src="humanvariabletransition.png" alt="humanvariabletransition.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-org79d6f4b" class="outline-3">
<h3 id="org79d6f4b"><span class="section-number-3">3.2</span> Comparison to Mathematical Models</h3>
<div class="outline-text-3" id="text-3-2">
<p>
To compare the similarities of the human <code>transition diagram</code>, a similar
<code>transition diagram</code> will be fixed on the basic principle of a <code>division
   algorithm</code>. The discussion will refer to this algorithm using the form \[N \setminus D
   = (Q,R),\] where:
</p>
<ul class="org-ul">
<li>\(N :=\) <code>Numerator</code> (<code>dividend</code>)</li>
<li>\(D :=\) <code>Denominator</code> (<code>divisor</code>)</li>
</ul>
<p>
is the input, and
</p>
<ul class="org-ul">
<li>\(Q :=\) <code>Quotient</code></li>
<li>\(R :=\) <code>Remainder</code></li>
</ul>
<p>
is the output.
</p>

<p>
Just as the lives of men unfortunately come to an end, so too does the life
of this <code>division algorithm</code>. It is thus called a <code>terminating algorithm</code>. As an
example on given inputs \(N = 96\) and \(D = 7\), the output is produced as \(Q =
   13\) and \(R = 5\).
</p>

<div class="figure">
<p><img src="division.png" alt="division.png" />
</p>
</div>

<p>
At this point, <code>transition diagram</code> does not show the <code>division algorithm</code> to be
very algorithmic. The <code>transition diagram</code> only includes one <code>transition</code> when
usually an algorithm involves a series of steps. Thus in the same way that
the life of the man was expanded earlier, the steps of the algorithm can be
expanded. The <code>division algorithm</code> as above can be defined in an innumerable
number of ways by being tricky. To keep things simple, however, the
definition of the <code>division algorithm</code> here will use the method presented in
Euclid's <i>Elements</i>, which finds the remainder upon division using only
subtractions and comparisons. At each transition, the step number is
incremented and the value of the <code>denominator</code> is subtracted from the
<code>numerator</code>. When the <code>denominator</code> can no longer be negated from the <code>numerator</code>
without producing a negative number, the algorithm terminates. The <code>singular</code>
<code>transition diagram</code> of this algorithm follows from the full division process
figure.
</p>

<div class="figure">
<p><img src="divisionrigourous.png" alt="divisionrigourous.png" />
</p>
<p><span class="figure-number">Figure 7: </span>full division process</p>
</div>

<p>
Returning to the human automaton analogy where the <code>transitions</code> of the man
could be <code>variable</code>, the <code>transitions</code> of the division can be made <code>variable</code> also.
One who is well-versed in the ways of dividing numbers could consider first
doing \(10\) steps of the <code>division algorithm</code> in one fell swoop, moving from the
\(0^{th}\) step to an alternative \(10^{th}\) step, at which point one could notice
that moving \(3\) steps forward&#x2014;to that of the alternative \(13^{th}\)
step&#x2014;would be the maximum number of additional steps possible to take.
Another person might do the normal algorithm until he/she reaches the \(3^{rd}\) step
of the algorithm, at which point the <code>numerator</code> sits at \(75\), a number
reducible to \(10\) additional steps of the <code>division algorithm</code> all at once,
making it obvious to move to the alternative \(13^{th}\) step of the algorithm by
the reason that the <code>numerator</code> \(75\) is at most \(10\) of the <code>denominator</code> \(7\).
This is detailed in the full division process with variability figure.
</p>

<div class="figure">
<p><img src="divisionrigourouswithalts.png" alt="divisionrigourouswithalts.png" />
</p>
<p><span class="figure-number">Figure 8: </span>full division process with variability</p>
</div>

<p>
As a remark, this sort of diagram is analogous to how the neurons of a human
brain work. In this example the analogy should be particularly obvious. A
person who is very well-versed in the ways of division would not have a hard
time at all moving through this diagram to produce the answer. That is, the
network of neurons in his/her head which facilitate the production of the
solution is <i>myelinated</i>. Some of the <code>variable</code> <code>transitions</code> of this diagram
which facilitate the retrieval of the final solution or of the neural network
in the brain of the well-versed human divider are correspondingly properly
<i>myelinated</i>, and therefore the decision-making process which results in the
movement through either is very rapid. Markov chains are considered the
probabilistic analogous to automatons, and could facilitate in making the
analogy between the <code>transition diagram</code> and the neural networks of the human
brain.
</p>
</div>
</div>

<div id="outline-container-org815ba0d" class="outline-3">
<h3 id="org815ba0d"><span class="section-number-3">3.3</span> AI-hard</h3>
<div class="outline-text-3" id="text-3-3">
<p>
Constructing a kind of <code>human automaton</code> for the purpose of understanding
natural language is the <code>Natural Language Understanding</code> (NLU) problem in the
field of artificial intelligence. It is an AI-hard problem, and it is said
that <i>simulating</i> a machine which understands natural language completely
corresponds to <i>duplicating</i> human intelligence.
</p>

<p>
The study of language is typically divided into three separate categories:
syntax, semantics, and pragmatics. Pragmatics is, essentially, how syntax and
semantics operate together to formulate language, so pragmatics in the study
of language here will be ignored. The point of this paper ultimately answers
the question supposed by pragmatics, so specifically concerning ourselves
with pragmatics is metalogically useless. The other two categories, however,
provide the very questions that need to be answered. Since computers are
syntactically bound, the question posed by syntax becomes a question of
logistics; that is, how the structure of the computational model should be.
This is a question best left to the implementation details, which is better
considered later. The other category, semantics, poses a tricky problem
inherent to the study of AI.
</p>

<p>
Thus far, there has been provided a simple construction of the syntactical
elements necessary for computers to develop its understanding of language;
syntactical understanding of phrases is naturally very computational, because
computation itself relies specifically on the elements of syntax. The bigger
problem in the field lies in a computer's inability to provide semantic
information to the understanding of language. When a human hears or reads a
natural language statement, his/her understanding of the statement is facilitated
by a robust understanding of the meaning of the words and phrases inherent to
the statement. A computer looking only into the syntactical derivation of a
statement still has no conscience understanding of the words or phrases; and
therefore could not possibly understand the statement. It makes sense then
that providing a method by which computers could understand the words,
phrases, and statements therefore provides the computer with intelligence;
possibly even implying that the computer is being provided with
consciousness.
</p>

<p>
In any case, to begin to at least simulate the way in which a human might
think about the world, let us continue to consider how the notion of the
<code>transition diagram</code> might be able to operate as a <code>context</code>, beginning this
intelligence-simulating path.
</p>
</div>
</div>
</div>

<div id="outline-container-org0779bee" class="outline-2">
<h2 id="org0779bee"><span class="section-number-2">4</span> Context Generation</h2>
<div class="outline-text-2" id="text-4">
</div><div id="outline-container-orgce0a257" class="outline-3">
<h3 id="orgce0a257"><span class="section-number-3">4.1</span> Rules of Inference</h3>
<div class="outline-text-3" id="text-4-1">
<p>
The ideal method to derive the logic from a given context lies in a deductive
reasoning system. That is, given some antecedent statement \(A\), one wants to
infer \(B\) by some implication \(A \rightarrow B\). Since \(A\) was given, one can write \(A,
   A \rightarrow B\). Then, by <i>modus ponens</i>, \(A, A \rightarrow B \vdash B\). Unfortunately, using
deductive reasoning in a human environment is not always possible. Human
thought is causal. A human takes some sensory stimulus from one of his/her
senses which in turn inspires some thought relevant to his/her context. The
conclusion is some epistemically objective, observer independent observation
holding true, and the thoughts are what is inferred about the conclusion; the
observer wants to believe that his/her thoughts, the inferred antecedent
logic, led to the conclusion witnessed. Thus in a human environment one must
use an abductive reasoning system. A stimulus causes one to derive an
implication from his/her context which led to the conclusion, wherein the
statements of the context function as the antecedent which hypothetically
imply the conclusion. That is, one would like to say that \(A, B \vdash A \rightarrow
   B\). However, given the definition of &rarr;, this goes against the definition of
the <code>first-order language</code>.
</p>

<p>
From a computational standpoint, it may be hard to determine which antecedent
context possibly leads to the hypothetical implication as well. A human has a
limitless reference bank to which his thoughts may traverse. Given a sequence
of contextual statements \(A_1, A_2, ... A_n\) how could one determine which
statement, or set of statements \(X \sube \{ A_1, A_2, ..., A_n \}\) actually led to
the hypothetical implication of the statement \(B\)? Written \[\left(
   \bigwedge_{x \in X}x, B \right) \vdash \left( \left(\bigwedge_{x \in X}x \right)
   \rightarrow B \right).\]
</p>
</div>
</div>

<div id="outline-container-org613296a" class="outline-3">
<h3 id="org613296a"><span class="section-number-3">4.2</span> Language Generation</h3>
<div class="outline-text-3" id="text-4-2">
<p>
Let there be a <code>context-free grammar</code> consisting of
</p>
<ul class="org-ul">
<li>verbs <i>see</i>, <i>kiss</i>, <i>tell</i>, <i>like</i>, and <i>love</i>;</li>
<li>proper nouns Kim, Tom, Mary, and Sally;</li>
<li>subordinating conjunction <i>that</i>; and</li>
<li>unary logical operator <b>not</b> (mask-able as <b>neither</b>&hellip; <b>nor</b>, or <b>no</b> where
convenient).</li>
</ul>

<p>
The following is a <code>transition diagram</code> implementing statements possibly
generated by the <code>context-free grammar</code>. Note in this <code>transition diagram</code> how
<code>transitions</code> and <code>events</code> are treated similarly. Note also that <code>events</code> in this
diagram are <code>reactive</code>, meaning one <code>event</code> <code>deterministically</code> causes the next
<code>event</code>; so the <code>resultant transition</code> points to another <code>event</code>. This <code>transition
   diagram</code> possibly produces something in the <code>natural language</code> English as "Tom
kisses Sally, but Kim sees Tom kissing Sally. Later Kim tells Mary that she
saw Tom kissing Sally. Now neither Mary nor Kim like Tom."
</p>

<div class="figure">
<p><img src="kissseeevent.png" alt="kissseeevent.png" />
</p>
</div>

<p>
This <code>transition diagram</code> represents a <code>singular</code> <code>context</code> by which some person,
or some automaton, interprets a series of <code>events</code>. There are, however, other
possibilities by which this series of <code>events</code> could have unfolded themselves;
considerations of these other possibilities generate <code>non-deterministic</code>,
<code>variable transitions</code> in a more complex <code>transition diagram</code>.
</p>

<p>
The following <code>variable transition diagram</code> takes into consideration the
possibility that Kim <i>does <b>not</b> tell</i> Mary <i>that</i> Tom <i>was kissing</i> Sally. This is
represented by the changing of the <code>singular transition</code> previously
transitioning Kim into <i>telling</i> Mary <i>that</i> Tom <i>was kissing</i> Sally into <code>variable
   transitions</code>: one the same as before, the other two such that Kim does not
inspire any <code>events</code>, but does transition her into possibly feeling differently
about Tom (either she continues to <i>like</i> Tom, or she finds that the event
transitions her into <i><b>not</b> liking</i> Tom anymore). When Kim does not transition
herself into the <i>telling</i> Mary <i>that</i> Tom <i>was kissing</i> Sally, however, the <code>event</code>
inspired by Kim <i>seeing</i> Tom <i>kissing</i> Sally fails to transition Mary into a next
appropriate <code>state</code>. Thus there needs to be more <code>variable transitions</code> made so
that Mary can find herself somewhere later in the <code>transition diagram</code>. Since
there was no new <code>event</code> to inspire Mary to be anywhere, the new event by which
she transitions herself is <code>idempotent</code>, or does nothing, but satisfies the
requirement that she finds herself in an acceptable state later in the
<code>transition diagram</code>. That is, Mary <i>loves</i> Tom in the beginning of the diagram,
and Mary <i>loves</i> Tom at the end of the diagram.
</p>

<p>
There are also new <code>variable transitions</code> and new <code>events</code> made to detail the
different possible inspirations that the <code>event</code> might have had on the two
people in the Kim <i>telling</i> Mary that Tom <i>was kissing</i> Sally <code>event</code>. Perhaps Mary
continues to <i>love</i> Tom even after the conversation, or perhaps she is reduced
to only <i>liking</i> Tom, or perhaps she decides that she <i><b>no</b> longer likes</i> Tom.
Kim would likely transition into either liking Tom or <i><b>not</b> liking</i> Tom, but
the possibility that she somehow <i>loves</i> Tom after the conversation is not
ruled out as a possibility either.
</p>

<p>
Finally, the <code>events</code> previously described to be <code>reactive events</code> that were
previously <code>deterministic</code>, but now made to be <code>non-deterministic</code>, are called
<code>promised events</code> (that is, the <code>event</code> may not happen because events can be
canceled in the same way that promises can be broken).
</p>

<div class="figure">
<p><img src="kissseeeventcontextreconciliation.png" alt="kissseeeventcontextreconciliation.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-orgdaf8e70" class="outline-3">
<h3 id="orgdaf8e70"><span class="section-number-3">4.3</span> Logic Generation</h3>
<div class="outline-text-3" id="text-4-3">
<p>
Let's take a step back to the very beginning. The <code>natural language</code> sentence
constructed from the <code>singular context</code> was "Tom kisses Sally, but Kim sees Tom
kissing Sally. Later Kim tells Mary that she saw Tom kissing Sally. Now
neither Mary nor Kim like Tom." Let's consider writing this sentence as
statements generate-able by some <code>context-free grammar</code>:
</p>
<dl class="org-dl">
<dt>P<sub>1</sub></dt><dd>Tom <i>kisses</i> Sally,</dd>
<dt>P<sub>2</sub></dt><dd>Kim <i>sees</i> Tom <i>kissing</i> Sally,</dd>
<dt>P<sub>3</sub></dt><dd>Kim <i>tells</i> Mary <i>that</i> Tom <i>was kissing</i> Sally,</dd>
<dt>Q<sub>1</sub></dt><dd>Kim <i>does <b>not</b> like</i> Tom, and</dd>
<dt>Q<sub>2</sub></dt><dd>Mary <i>does <b>not</b> like</i> Tom.</dd>
</dl>


<p>
The <code>natural language</code> sentence "Tom kisses Sally, but Kim sees Tom kissing
Sally" can be formulated as a <code>first-order logic</code> statement \(P_1 \land P_2\). This
statement logical implies the following <code>event</code> which corresponds to the
<code>natural language</code> sentence "Kim tells Mary that Tom was kissing Sally." So,
\((P_1 \land P_2) \vdash P_3\). The ensemble of each of these <code>events</code>, and their
corresponding statements, results in the logical implication of the
first-order logic statement \(Q_1 \land Q_2\). In sum, \[((P_1 \land P_2) \vdash
   P_3) \vdash (Q_1 \land Q_2).\]
</p>

<p>
Written in our example <code>first-order language</code> (again by a bit of hand-waving),
this is tautologically equivalent to \[(\neg(P_1 \rightarrow \neg P_2) \vdash P_3)
   \vdash \neg(Q_1 \rightarrow \neg Q_2).\]
</p>

<p>
As before, let's start by assuming that our consequent was true, <i>i.e.</i> that
statement \(\neg(Q_1 \rightarrow \neg Q_2)\) holds. This statement holds when the
statement \(Q_1 \rightarrow \neg Q_2\) does not hold, or when \(Q_1\) holds but
\(\neg Q_2\) does not. \(Q_1\) holding means that "Kim <i>does <b>not</b> like</i> Tom" is a true
statement. \(\neg Q_2\) does not hold when \(Q_2\) does hold, so "Mary <i>does <b>not</b> like</i>
Tom" is a true statement. The antecedent of the logical implication must hold
because \((\neg(P_1 \rightarrow \neg P_2) \vdash P_3)\) logically implies the
consequent, and the consequent holds. Thus \((\neg(P_1 \rightarrow \neg P_2) \vdash
   P_3)\) means that \(\neg(P_1 \rightarrow \neg P_2)\) holds so that \(P_3\) holds. \(P_3\)
holding corresponds to the statement "Kim <i>tells</i> Mary <i>that</i> Tom <i>was kissing</i>
Sally" being true. (Note the correspondence of this <code>first-order logic</code>
statement \(P_3\) to that of the two <code>transition diagrams</code> from before. In the
<code>singular context</code> it is asserted, via the usage of the \(\vdash\) symbol, that
the <code>event</code> corresponding to the statement \(P_3\) actually happened because the
two events corresponding to \(P_1\) and \(P_2\) actually happened. The previous two
<code>events</code> happening, corresponding to \(P_1\) and \(P_2\) holding, logically implies
the happening of the <code>event</code> in correspondence with \(P_3\).) Since \(\neg(P_1
   \rightarrow \neg P_2)\) holds, it must be that \(P_1 \rightarrow \neg P_2\) does not hold. \(P_1
   \rightarrow \neg P_2\) does not hold when \(P_1\) holds, but \(\neg P_2\) does not, or \(P_2\) does
hold. Thus, it is that the sentence "Tom <i>kisses</i> Sally" is true, and the
sentence "Kim <i>sees</i> Tom <i>kissing</i> Sally" is true.
</p>

<p>
As before when constructing the <code>variable transition diagram</code>, the same
consideration that the <code>event</code> corresponding to statement \(P_3\) not happening
will be made. This changing of the diagram corresponds to a changing of the
<code>first-order logic</code>. The first-order statement \[(\neg(P_1 \rightarrow \neg P_2)
   \vdash P_3) \vdash \neg(Q_1 \rightarrow \neg Q_2).\] becomes \[(\neg(P_1 \rightarrow
   \neg P_2) \rightarrow P_3) \vdash \neg(Q_1 \rightarrow \neg Q_2).\] As such, no longer does the
statement \(\neg(P_1 \rightarrow \neg P_2)\) logically imply \(P_3\), and it is no
longer possible to deduce absolute truth from the statement. \((\neg(P_1
   \rightarrow \neg P_2) \rightarrow P_3)\) does not hold when the statement \(\neg(P_1 \rightarrow \neg P_2)\)
holds, and \(P_3\) does not. Since we are making the consideration that "Kim
<i>does <b>not</b> tell</i> Mary <i>that</i> Tom <i>was kissing</i> Sally," then \(\neg P_3\) holds and
therefore \(P_3\) does not. Therefore the statement \((\neg(P_1 \rightarrow \neg P_2)
   \rightarrow P_3)\) does not hold. Furthermore, it does not hold that \[(\neg(P_1 \rightarrow
   \neg P_2) \rightarrow P_3) \vdash \neg(Q_1 \rightarrow \neg Q_2),\] but it can be reconstructed
as \[(\neg(P_1 \rightarrow \neg P_2) \rightarrow P_3) \rightarrow \neg(Q_1
   \rightarrow \neg Q_2).\] This corresponds to the considerations that were made in the
reconstruction of the <code>singular transition diagram</code> to the <code>variable transition
   diagram</code>. Since the statement \((\neg(P_1 \rightarrow \neg P_2) \rightarrow P_3)\)
does not hold, then the consequent \(\neg(Q_1 \rightarrow \neg Q_2)\) could either
hold or not hold for the statement \((\neg(P_1 \rightarrow \neg P_2) \rightarrow
   P_3) \rightarrow \neg(Q_1 \rightarrow \neg Q_2)\) to hold. This means that either \(Q_1\) or
\(\neg Q_1\) could hold, and either \(Q_2\) or \(\neg Q_2\) could hold. \(Q_1\) holding means
that "Kim <i>does <b>not</b> like</i> Tom," while \(\neg Q_1\) holding means that "Kim <i>does like</i>
Tom." \(Q_2\) holding means that "Mary <i>does <b>not</b> like</i> Tom" (or possibly "Mary
<i>loves</i> Tom"), while \(\neg Q_2\) means that "Mary <i>does like</i> Tom."
</p>

<p>
Possible new <code>natural language</code> sentences may be derived and verified as
follows:
</p>
<ul class="org-ul">
<li>"Tom kisses Sally, but Kim sees Tom kissing Sally. Later Kim doesn't tell
Mary that she saw Tom kissing Sally. Mary still loves Tom, while Kim has
come to not like Tom."</li>
<li>"Tom kisses Sally, but Kim sees Tom kissing Sally. Later Kim doesn't tell
Mary that she saw Tom kissing Sally. Mary still loves Tom, and Kim still
likes Tom even though she knows Tom's little secret."</li>
<li>"Tom kisses Sally, but Kim sees Tom kissing Sally. Later Kim doesn't tell
Mary that she saw Tom kissing Sally. Mary still loves Tom. Kim's knowing
the little secret about Tom and Sally has come to make her realize that she
herself loves Tom."</li>
</ul>
</div>
</div>

<div id="outline-container-org857e980" class="outline-3">
<h3 id="org857e980"><span class="section-number-3">4.4</span> Context Generation</h3>
<div class="outline-text-3" id="text-4-4">
<p>
The reorganizing and re-contextualizing of the <code>language generation</code> and <code>logic</code>
<code>generation</code> processes represents the idea of <code>context reconciliation</code>. In other
words, by taking a specific <code>singular context</code>, reconsidering an <code>event</code> of the
context and its resulting reconstruction of <code>events</code>, a <code>variable context</code> can be
created; there is a <code>first-order language</code> analogous to this reconsideration of
events and therefore a <code>computational model</code> capable of devising new,
meaningful <code>natural language</code> sentences given by the vocabulary inherent to the
<code>context-free grammar</code>.
</p>

<p>
This process, however, relies upon a need to have <code>contexts</code> already build into
the <code>automaton</code>. When trying to understand logic of a variable context, the
<code>automaton</code> looks upon <code>contexts</code> which it previously has verified.
</p>

<p>
The process is as follows, where \(\langle C \rangle\) is some new context taken from human
life, or generated by another automaton:
</p>
</div>
</div>
</div>

<div id="outline-container-org08e07ed" class="outline-2">
<h2 id="org08e07ed"><span class="section-number-2">5</span> Bibliography</h2>
<div class="outline-text-2" id="text-5">
<ul class="org-ul">
<li>Boroditsky, Lera; Schmidt, Lauren; Phillips, Webb, "Sex, syntax, and
semantics" (PDF), Language in Mind: Advances in the Study of Language and
Thought, pp. 61–79</li>
<li>Carroll, Lewis (1896). Symbolic Logic. London, New York, Macmillan.</li>
<li>Euclid, ., Heath, T. L., &amp; Densmore, D. (2002). Euclid's Elements: All
thirteen books complete in one volume : the Thomas L. Heath translation.
Santa Fe, N.M: Green Lion Press.</li>
<li>Koutsofios, E., &amp; North, S. (1996). Drawing graphs with dot. dot User's
Manual, AT&amp;T Bell Laboratories, Murray Hill, NJ.</li>
<li>Ovchinnikova, E. (2012). Integration of World Knowledge for Natural Language
Understanding Volume 3 of the series Atlantis Thinking Machines pp 15-37.
Atlantis Press.</li>
<li>Pustejovsky J., et. al. (2006) TimeML Annotation Guidelines Version 1.2.1.</li>
</ul>

<ul class="org-ul">
<li>Sipser, M. (2006). Introduction to the theory of computation. Boston:
Thomson Course Technology.</li>
<li>Spinoza, B. ., Hampshire, S., &amp; Curley, E. M. (1996). Ethics. London:
Penguin Books.</li>
</ul>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1">1</a></sup> <div class="footpara"><p class="footpara">
where the square represents an <code>event</code> in time, the circles represent the
<code>states</code> of the person, and the arrows are the <code>transitions</code> between the
objects&#x2014;the dotted arrow is a <code>resultant transition</code>, indicating that an event
results in a state of being whereas the solid arrow is a <code>traditional
transition</code>&#x2014;or just a <code>transition</code>&#x2014;indicating the change from one <code>state</code> to
another <code>state</code>.
</p></div></div>

<div class="footdef"><sup><a id="fn.2" class="footnum" href="#fnr.2">2</a></sup> <div class="footpara"><p class="footpara">
The open dot at the end of a transition refers to the transition being
<code>variable</code>. In some cases it may also be referred to as <code>non-deterministic</code>, as a
<code>singular</code> decision cannot be <code>deterministic</code> given <code>variable transitions</code>.
</p></div></div>


</div>
</div></div>
<div id="postamble" class="status">
<p class="author">Author: Justen Rickert</p>
<p class="date">Created: 2017-05-09 Tue 01:03</p>
<p class="validation"></p>
</div>
</body>
</html>
